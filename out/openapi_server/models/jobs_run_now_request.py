# coding: utf-8

from __future__ import absolute_import
from datetime import date, datetime  # noqa: F401

from typing import List, Dict  # noqa: F401

from openapi_server.models.base_model_ import Model
from openapi_server.models.run_now_input import RunNowInput
from openapi_server.models.run_parameters import RunParameters
from openapi_server import util

from openapi_server.models.run_now_input import RunNowInput  # noqa: E501
from openapi_server.models.run_parameters import RunParameters  # noqa: E501

class JobsRunNowRequest(Model):
    """NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).

    Do not edit the class manually.
    """

    def __init__(self, job_id=None, idempotency_token=None, jar_params=None, notebook_params=None, python_params=None, spark_submit_params=None, python_named_params=None):  # noqa: E501
        """JobsRunNowRequest - a model defined in OpenAPI

        :param job_id: The job_id of this JobsRunNowRequest.  # noqa: E501
        :type job_id: int
        :param idempotency_token: The idempotency_token of this JobsRunNowRequest.  # noqa: E501
        :type idempotency_token: str
        :param jar_params: The jar_params of this JobsRunNowRequest.  # noqa: E501
        :type jar_params: List[str]
        :param notebook_params: The notebook_params of this JobsRunNowRequest.  # noqa: E501
        :type notebook_params: Dict[str, object]
        :param python_params: The python_params of this JobsRunNowRequest.  # noqa: E501
        :type python_params: List[str]
        :param spark_submit_params: The spark_submit_params of this JobsRunNowRequest.  # noqa: E501
        :type spark_submit_params: List[str]
        :param python_named_params: The python_named_params of this JobsRunNowRequest.  # noqa: E501
        :type python_named_params: object
        """
        self.openapi_types = {
            'job_id': int,
            'idempotency_token': str,
            'jar_params': List[str],
            'notebook_params': Dict[str, object],
            'python_params': List[str],
            'spark_submit_params': List[str],
            'python_named_params': object
        }

        self.attribute_map = {
            'job_id': 'job_id',
            'idempotency_token': 'idempotency_token',
            'jar_params': 'jar_params',
            'notebook_params': 'notebook_params',
            'python_params': 'python_params',
            'spark_submit_params': 'spark_submit_params',
            'python_named_params': 'python_named_params'
        }

        self._job_id = job_id
        self._idempotency_token = idempotency_token
        self._jar_params = jar_params
        self._notebook_params = notebook_params
        self._python_params = python_params
        self._spark_submit_params = spark_submit_params
        self._python_named_params = python_named_params

    @classmethod
    def from_dict(cls, dikt) -> 'JobsRunNowRequest':
        """Returns the dict as a model

        :param dikt: A dict.
        :type: dict
        :return: The JobsRunNow_request of this JobsRunNowRequest.  # noqa: E501
        :rtype: JobsRunNowRequest
        """
        return util.deserialize_model(dikt, cls)

    @property
    def job_id(self):
        """Gets the job_id of this JobsRunNowRequest.

        The ID of the job to be executed  # noqa: E501

        :return: The job_id of this JobsRunNowRequest.
        :rtype: int
        """
        return self._job_id

    @job_id.setter
    def job_id(self, job_id):
        """Sets the job_id of this JobsRunNowRequest.

        The ID of the job to be executed  # noqa: E501

        :param job_id: The job_id of this JobsRunNowRequest.
        :type job_id: int
        """

        self._job_id = job_id

    @property
    def idempotency_token(self):
        """Gets the idempotency_token of this JobsRunNowRequest.

        An optional token to guarantee the idempotency of job run requests. If a run with the provided token already exists, the request does not create a new run but returns the ID of the existing run instead.  If you specify the idempotency token, upon failure you can retry until the request succeeds. Databricks guarantees that exactly one run is launched with that idempotency token.  This token must have at most 64 characters.  For more information, see [How to ensure idempotency for jobs](https://kb.databricks.com/jobs/jobs-idempotency.html).  # noqa: E501

        :return: The idempotency_token of this JobsRunNowRequest.
        :rtype: str
        """
        return self._idempotency_token

    @idempotency_token.setter
    def idempotency_token(self, idempotency_token):
        """Sets the idempotency_token of this JobsRunNowRequest.

        An optional token to guarantee the idempotency of job run requests. If a run with the provided token already exists, the request does not create a new run but returns the ID of the existing run instead.  If you specify the idempotency token, upon failure you can retry until the request succeeds. Databricks guarantees that exactly one run is launched with that idempotency token.  This token must have at most 64 characters.  For more information, see [How to ensure idempotency for jobs](https://kb.databricks.com/jobs/jobs-idempotency.html).  # noqa: E501

        :param idempotency_token: The idempotency_token of this JobsRunNowRequest.
        :type idempotency_token: str
        """

        self._idempotency_token = idempotency_token

    @property
    def jar_params(self):
        """Gets the jar_params of this JobsRunNowRequest.

        A list of parameters for jobs with Spark JAR tasks, for example `\"jar_params\": [\"john doe\", \"35\"]`. The parameters are used to invoke the main function of the main class specified in the Spark JAR task. If not specified upon `run-now`, it defaults to an empty list. jar_params cannot be specified in conjunction with notebook_params. The JSON representation of this field (for example `{\"jar_params\":[\"john doe\",\"35\"]}`) cannot exceed 10,000 bytes.  Use [Task parameter variables](https://docs.databricks.com/jobs.html#parameter-variables) to set parameters containing information about job runs.  # noqa: E501

        :return: The jar_params of this JobsRunNowRequest.
        :rtype: List[str]
        """
        return self._jar_params

    @jar_params.setter
    def jar_params(self, jar_params):
        """Sets the jar_params of this JobsRunNowRequest.

        A list of parameters for jobs with Spark JAR tasks, for example `\"jar_params\": [\"john doe\", \"35\"]`. The parameters are used to invoke the main function of the main class specified in the Spark JAR task. If not specified upon `run-now`, it defaults to an empty list. jar_params cannot be specified in conjunction with notebook_params. The JSON representation of this field (for example `{\"jar_params\":[\"john doe\",\"35\"]}`) cannot exceed 10,000 bytes.  Use [Task parameter variables](https://docs.databricks.com/jobs.html#parameter-variables) to set parameters containing information about job runs.  # noqa: E501

        :param jar_params: The jar_params of this JobsRunNowRequest.
        :type jar_params: List[str]
        """

        self._jar_params = jar_params

    @property
    def notebook_params(self):
        """Gets the notebook_params of this JobsRunNowRequest.

        A map from keys to values for jobs with notebook task, for example `\"notebook_params\": {\"name\": \"john doe\", \"age\": \"35\"}`. The map is passed to the notebook and is accessible through the [dbutils.widgets.get](https://docs.databricks.com/dev-tools/databricks-utils.html#dbutils-widgets) function.  If not specified upon `run-now`, the triggered run uses the job’s base parameters.  notebook_params cannot be specified in conjunction with jar_params.  Use [Task parameter variables](https://docs.databricks.com/jobs.html#parameter-variables) to set parameters containing information about job runs.  The JSON representation of this field (for example `{\"notebook_params\":{\"name\":\"john doe\",\"age\":\"35\"}}`) cannot exceed 10,000 bytes.  # noqa: E501

        :return: The notebook_params of this JobsRunNowRequest.
        :rtype: Dict[str, object]
        """
        return self._notebook_params

    @notebook_params.setter
    def notebook_params(self, notebook_params):
        """Sets the notebook_params of this JobsRunNowRequest.

        A map from keys to values for jobs with notebook task, for example `\"notebook_params\": {\"name\": \"john doe\", \"age\": \"35\"}`. The map is passed to the notebook and is accessible through the [dbutils.widgets.get](https://docs.databricks.com/dev-tools/databricks-utils.html#dbutils-widgets) function.  If not specified upon `run-now`, the triggered run uses the job’s base parameters.  notebook_params cannot be specified in conjunction with jar_params.  Use [Task parameter variables](https://docs.databricks.com/jobs.html#parameter-variables) to set parameters containing information about job runs.  The JSON representation of this field (for example `{\"notebook_params\":{\"name\":\"john doe\",\"age\":\"35\"}}`) cannot exceed 10,000 bytes.  # noqa: E501

        :param notebook_params: The notebook_params of this JobsRunNowRequest.
        :type notebook_params: Dict[str, object]
        """

        self._notebook_params = notebook_params

    @property
    def python_params(self):
        """Gets the python_params of this JobsRunNowRequest.

        A list of parameters for jobs with Python tasks, for example `\"python_params\": [\"john doe\", \"35\"]`. The parameters are passed to Python file as command-line parameters. If specified upon `run-now`, it would overwrite the parameters specified in job setting. The JSON representation of this field (for example `{\"python_params\":[\"john doe\",\"35\"]}`) cannot exceed 10,000 bytes.  Use [Task parameter variables](https://docs.databricks.com/jobs.html#parameter-variables) to set parameters containing information about job runs.  Important  These parameters accept only Latin characters (ASCII character set). Using non-ASCII characters returns an error. Examples of invalid, non-ASCII characters are Chinese, Japanese kanjis, and emojis.  # noqa: E501

        :return: The python_params of this JobsRunNowRequest.
        :rtype: List[str]
        """
        return self._python_params

    @python_params.setter
    def python_params(self, python_params):
        """Sets the python_params of this JobsRunNowRequest.

        A list of parameters for jobs with Python tasks, for example `\"python_params\": [\"john doe\", \"35\"]`. The parameters are passed to Python file as command-line parameters. If specified upon `run-now`, it would overwrite the parameters specified in job setting. The JSON representation of this field (for example `{\"python_params\":[\"john doe\",\"35\"]}`) cannot exceed 10,000 bytes.  Use [Task parameter variables](https://docs.databricks.com/jobs.html#parameter-variables) to set parameters containing information about job runs.  Important  These parameters accept only Latin characters (ASCII character set). Using non-ASCII characters returns an error. Examples of invalid, non-ASCII characters are Chinese, Japanese kanjis, and emojis.  # noqa: E501

        :param python_params: The python_params of this JobsRunNowRequest.
        :type python_params: List[str]
        """

        self._python_params = python_params

    @property
    def spark_submit_params(self):
        """Gets the spark_submit_params of this JobsRunNowRequest.

        A list of parameters for jobs with spark submit task, for example `\"spark_submit_params\": [\"--class\", \"org.apache.spark.examples.SparkPi\"]`. The parameters are passed to spark-submit script as command-line parameters. If specified upon `run-now`, it would overwrite the parameters specified in job setting. The JSON representation of this field (for example `{\"python_params\":[\"john doe\",\"35\"]}`) cannot exceed 10,000 bytes.  Use [Task parameter variables](https://docs.databricks.com/jobs.html#parameter-variables) to set parameters containing information about job runs.  Important  These parameters accept only Latin characters (ASCII character set). Using non-ASCII characters returns an error. Examples of invalid, non-ASCII characters are Chinese, Japanese kanjis, and emojis.  # noqa: E501

        :return: The spark_submit_params of this JobsRunNowRequest.
        :rtype: List[str]
        """
        return self._spark_submit_params

    @spark_submit_params.setter
    def spark_submit_params(self, spark_submit_params):
        """Sets the spark_submit_params of this JobsRunNowRequest.

        A list of parameters for jobs with spark submit task, for example `\"spark_submit_params\": [\"--class\", \"org.apache.spark.examples.SparkPi\"]`. The parameters are passed to spark-submit script as command-line parameters. If specified upon `run-now`, it would overwrite the parameters specified in job setting. The JSON representation of this field (for example `{\"python_params\":[\"john doe\",\"35\"]}`) cannot exceed 10,000 bytes.  Use [Task parameter variables](https://docs.databricks.com/jobs.html#parameter-variables) to set parameters containing information about job runs.  Important  These parameters accept only Latin characters (ASCII character set). Using non-ASCII characters returns an error. Examples of invalid, non-ASCII characters are Chinese, Japanese kanjis, and emojis.  # noqa: E501

        :param spark_submit_params: The spark_submit_params of this JobsRunNowRequest.
        :type spark_submit_params: List[str]
        """

        self._spark_submit_params = spark_submit_params

    @property
    def python_named_params(self):
        """Gets the python_named_params of this JobsRunNowRequest.

        A map from keys to values for jobs with Python wheel task, for example `\"python_named_params\": {\"name\": \"task\", \"data\": \"dbfs:/path/to/data.json\"}`.  # noqa: E501

        :return: The python_named_params of this JobsRunNowRequest.
        :rtype: object
        """
        return self._python_named_params

    @python_named_params.setter
    def python_named_params(self, python_named_params):
        """Sets the python_named_params of this JobsRunNowRequest.

        A map from keys to values for jobs with Python wheel task, for example `\"python_named_params\": {\"name\": \"task\", \"data\": \"dbfs:/path/to/data.json\"}`.  # noqa: E501

        :param python_named_params: The python_named_params of this JobsRunNowRequest.
        :type python_named_params: object
        """

        self._python_named_params = python_named_params
