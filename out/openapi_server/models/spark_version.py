# coding: utf-8

from __future__ import absolute_import
from datetime import date, datetime  # noqa: F401

from typing import List, Dict  # noqa: F401

from openapi_server.models.base_model_ import Model
from openapi_server import util


class SparkVersion(Model):
    """NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).

    Do not edit the class manually.
    """

    def __init__(self, key=None, name=None):  # noqa: E501
        """SparkVersion - a model defined in OpenAPI

        :param key: The key of this SparkVersion.  # noqa: E501
        :type key: str
        :param name: The name of this SparkVersion.  # noqa: E501
        :type name: str
        """
        self.openapi_types = {
            'key': str,
            'name': str
        }

        self.attribute_map = {
            'key': 'key',
            'name': 'name'
        }

        self._key = key
        self._name = name

    @classmethod
    def from_dict(cls, dikt) -> 'SparkVersion':
        """Returns the dict as a model

        :param dikt: A dict.
        :type: dict
        :return: The SparkVersion of this SparkVersion.  # noqa: E501
        :rtype: SparkVersion
        """
        return util.deserialize_model(dikt, cls)

    @property
    def key(self):
        """Gets the key of this SparkVersion.

        [Databricks Runtime version](https://docs.databricks.com/dev-tools/api/latest/index.html#programmatic-version) key, for example `7.3.x-scala2.12`. The value that must be provided as the `spark_version` when creating a new cluster. The exact runtime version may change over time for a “wildcard” version (that is, `7.3.x-scala2.12` is a “wildcard” version) with minor bug fixes.  # noqa: E501

        :return: The key of this SparkVersion.
        :rtype: str
        """
        return self._key

    @key.setter
    def key(self, key):
        """Sets the key of this SparkVersion.

        [Databricks Runtime version](https://docs.databricks.com/dev-tools/api/latest/index.html#programmatic-version) key, for example `7.3.x-scala2.12`. The value that must be provided as the `spark_version` when creating a new cluster. The exact runtime version may change over time for a “wildcard” version (that is, `7.3.x-scala2.12` is a “wildcard” version) with minor bug fixes.  # noqa: E501

        :param key: The key of this SparkVersion.
        :type key: str
        """

        self._key = key

    @property
    def name(self):
        """Gets the name of this SparkVersion.

        A descriptive name for the runtime version, for example “Databricks Runtime 7.3 LTS”.  # noqa: E501

        :return: The name of this SparkVersion.
        :rtype: str
        """
        return self._name

    @name.setter
    def name(self, name):
        """Sets the name of this SparkVersion.

        A descriptive name for the runtime version, for example “Databricks Runtime 7.3 LTS”.  # noqa: E501

        :param name: The name of this SparkVersion.
        :type name: str
        """

        self._name = name
